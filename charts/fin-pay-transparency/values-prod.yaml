# Default values for fin-pay-transparency.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.
nameOverride: ""
fullnameOverride: ""
global:
  secrets:
    databasePassword: ~
    databaseName: ~
    databaseUser: ~
    adminKeycloakUrl: ~
    adminKeycloakClientId: ~
    adminKeycloakClientSecret: ~
    keycloakClientId: ~
    keycloakClientSecret: ~
    keycloakUrl: ~
    uiPrivateKey: ~
    uiPublicKey: ~
    bceidWsAuthPassword: ~
    bceidWsAuthUserName: ~
    bceidWsUrl: ~
    bceidWsOnlineServiceId: ~
    cssAppApiClientId: ~
    cssAppApiClientSecret: ~
    cssAppApiIntegrationId: ~
    cssAppApiEnvironment: "prod"
    externalConsumerApiKey: ~
    externalConsumerDeleteReportsApiKey: ~
    externalConsumerErrorReportsApiKey: ~
    chesClientID: ~
    chesTokenURL: ~
    chesClientSecret: ~
    chesAPIURL: ~
    chesEmailRecipients: ~
    annotation:
      helm.sh/policy: "keep"
  domain: "apps.silver.devops.gov.bc.ca" # it is required, apps.silver.devops.gov.bc.ca for silver cluster
  serverFrontend: ~
  autoscaling:
    enabled: true
  config:
    upload_file_max_size: "8388608"
    report_edit_duration_in_days: "30"
    report_unlock_duration_in_days: "2"
    template_path: "./dist/templates"
    # disable any crontime by setting it to ""
    delete_draft_report_cron_crontime: "0 0 * * *" # 12:00 AM PST/PDT
    delete_user_errors_cron_crontime: "" #(disabled) At 12:30 AM on the 1st day of every 6th month
    lock_report_cron_crontime: "15 0 * * *" # 12:15 AM PST/PDT
    expire_announcements_cron_crontime: "0 6,18 * * *" # 6am & 6pm daily
    delete_announcements_cron_crontime: "0 0 1 * *" # 1st day of every month
    email_expiring_announcements_cron_crontime: "0 7 * * *" # 7:00 AM PST/PDT
    enable_email_expiring_announcements: "true"
    reports_scheduler_cron_timezone: "America/Vancouver"
    first_year_with_prev_reporting_year_option: "2025"
    admin_invitation_duration_in_hours: "72"
    delete_announcements_duration_in_days: "90"
    db_connection_pool_size: "5"
    num_months_of_user_errors_to_keep: "6"
    is_user_error_logging_enabled: "true"
  crunchyEnabled: true
backend:
  enabled: true
  deploymentStrategy: RollingUpdate
  replicaCount: 1
  nameOverride: ""
  fullnameOverride: ""
  image:
    repository: ghcr.io/bcgov/fin-pay-transparency/backend
    repositoryInit: ghcr.io/bcgov/fin-pay-transparency/database-migrations
    pullPolicy: Always
    # Overrides the image tag whose default is the chart appVersion.
    tag: ~
  containerPort: 3000
  environment: production
  service:
    type: ClusterIP
    port: 80
    targetPort: 3000
  resources:
    requests:
      cpu: 150m
      memory: 600Mi
  initResources:
    requests:
      cpu: 150m
      memory: 250Mi

  autoscaling:
    enabled: true
    minReplicas: 3
    maxReplicas: 5
    targetCPUUtilizationPercentage: 60 # this percentage from request cpu
  storage:
    enabled: true
    size: 100Mi
    accessMode: ReadWriteMany
  app:
    env:
      siteminderLogoutEndpoint: https://logon7.gov.bc.ca/clp-cgi/logoff.cgi?retnow=1&returl=
      logLevel: info
      openshiftEnv: PROD

  podSecurityContext: {}
  securityContext: {}
  imagePullSecrets: []
  nodeSelector: {}
  tolerations: []
  pdb: true
frontend:
  enabled: true
  deploymentStrategy: RollingUpdate
  replicaCount: 1
  nameOverride: ""
  fullnameOverride: ""
  image:
    repository: ghcr.io/bcgov/fin-pay-transparency/frontend
    pullPolicy: Always
    # Overrides the image tag whose default is the chart appVersion.
    tag: ~
  containerPort: 3000
  environment: production
  route:
    enabled: true
    host: ""
    verificationPath: ""
  service:
    type: ClusterIP
    port: 80
    targetPort: 3000
  resources:
    requests:
      cpu: 50m
      memory: 150Mi
  env:
    logLevel: info
    snowplowUrl: spt.apps.gov.bc.ca
  autoscaling:
    enabled: true
    minReplicas: 3
    maxReplicas: 5
    targetCPUUtilizationPercentage: 80 # this percentage from request cpu

  podSecurityContext: {}
  securityContext:
    capabilities:
      add: ["NET_BIND_SERVICE"]
  imagePullSecrets: []
  nodeSelector: {}
  tolerations: []
  pdb: true

admin-frontend:
  env:
    isAdminAnalyticsAvailable: false
  
database:
  enabled: false
crunchy:
  enabled: true
  postgresVersion: 17
  imagePullPolicy: IfNotPresent
  # enable below to start a new crunchy cluster after disaster from a backed-up location, crunchy will choose the best place to recover from.
  # follow https://access.crunchydata.com/documentation/postgres-operator/5.2.0/tutorial/disaster-recovery/
  # Clone From Backups Stored in S3 / GCS / Azure Blob Storage
  # TESTED SUCCESSFULLY
  clone:
    enabled: false
    path: ~ # provide the proper path to source the cluster. ex: /backups/cluster/version/1, if current new cluster being created, this should be current cluster version -1, ideally
  # enable this to go back to a specific timestamp in history in the current cluster.
  # follow https://access.crunchydata.com/documentation/postgres-operator/5.2.0/tutorial/disaster-recovery/
  # Perform an In-Place Point-in-time-Recovery (PITR)
  # need to fire this command `oc annotate postgrescluster pay-transparency-tools-crunchy --overwrite postgres-operator.crunchydata.com/pgbackrest-restore=repo1`
  # NOT TESTED SUCCESSFULLY
  restore:
    enabled: false
    target: ~ # 2024-03-24 17:16:00-07 this is the target timestamp to go back to in current cluster
  instances:
    name: db
    metadata:
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "9187"
    replicas: 3
    dataVolumeClaimSpec:
      storage: 850Mi
      storageClassName: netapp-block-standard
    requests:
      cpu: 150m
      memory: 256Mi
    replicaCertCopy:
      requests:
        cpu: 20m
        memory: 32Mi

  pgBackRest:
    enabled: true
    backupPath: /backups/cluster/version
    clusterCounter: 1 # this is the number to identify what is the current counter for the cluster, each time it is cloned it should be incremented.
    image: # it's not necessary to specify an image as the images specified in the Crunchy Postgres Operator will be pulled by default
    # If retention-full-type set to 'count' then the oldest backups will expire when the number of backups reach the number defined in retention
    # If retention-full-type set to 'time' then the number defined in retention will take that many days worth of full backups before expiration
    retentionFullType: count
    s3:
      retention: "30"
      bucket: ~
      endpoint: ~
      accessKey: ~
      secretKey: ~
      fullBackupSchedule: 0 9 * * *
      incrementalBackupSchedule: "0 0,1,3,5,7,11,13,15,17,19,21,23 * * *" # every 2 hours, but 9 is not put intentionally to avoid conflict with full backup
    pvc:
      retention: "1"
      retentionFullType: count
      fullBackupSchedule: 0 8 * * *
      incrementalBackupSchedule: 0 0,4,12,16,20 * * *
      volume:
        accessModes: "ReadWriteOnce"
        storage: 1750Mi
        storageClassName: netapp-file-backup

    config:
      requests:
        cpu: 20m
        memory: 64Mi
    repoHost:
      requests:
        cpu: 200m
        memory: 256Mi
    sidecars:
      requests:
        cpu: 20m
        memory: 64Mi
    jobs:
      requests:
        cpu: 100m
        memory: 256Mi
  patroni:
    postgresql:
      pg_hba: "host all all 0.0.0.0/0 md5"
      parameters:
        shared_buffers: 16MB # default is 128MB; a good tuned default for shared_buffers is 25% of the memory allocated to the pod
        wal_buffers: "64kB" # this can be set to -1 to automatically set as 1/32 of shared_buffers or 64kB, whichever is larger
        min_wal_size: 32MB
        max_wal_size: 128MB # default is 1GB
        max_slot_wal_keep_size: 128MB # default is -1, allowing unlimited wal growth when replicas fall behind

  proxy:
    enabled: true
    pgBouncer:
      image: # it's not necessary to specify an image as the images specified in the Crunchy Postgres Operator will be pulled by default
      replicas: 2
      requests:
        cpu: 20m
        memory: 32Mi

  # Postgres Cluster resource values:
  pgmonitor:
    enabled: true
    exporter:
      image: # it's not necessary to specify an image as the images specified in the Crunchy Postgres Operator will be pulled by default
      requests:
        cpu: 35m
        memory: 32Mi
doc-gen-service:
  enabled: true
  deploymentStrategy: RollingUpdate
  replicaCount: 3
  nameOverride: ""
  fullnameOverride: ""
  image:
    repository: ghcr.io/bcgov/fin-pay-transparency/doc-gen-service
    pullPolicy: Always
    # Overrides the image tag whose default is the chart appVersion.
    tag: ~
  containerPort: 3000
  environment: production
  service:
    type: ClusterIP
    port: 80
    targetPort: 3000
  resources:
    requests:
      cpu: 500m
      memory: 350Mi

  podSecurityContext: {}
  securityContext: {}
  imagePullSecrets: []
  nodeSelector: {}
  tolerations: []
  pdb: true
backend-external:
  enabled: true
  deploymentStrategy: Recreate
  replicaCount: 2
  nameOverride: ""
  fullnameOverride: ""
  image:
    repository: ghcr.io/bcgov/fin-pay-transparency/backend-external
    pullPolicy: Always
    # Overrides the image tag whose default is the chart appVersion.
    tag: ~
  containerPort: 3000
  environment: production
  service:
    type: ClusterIP
    port: 80
    targetPort: 3000
  resources:
    requests:
      cpu: 20m
      memory: 150Mi
  app:
    env:
      logLevel: info

  podSecurityContext: {}
  securityContext: {}
  imagePullSecrets: []
  nodeSelector: {}
  tolerations: []
